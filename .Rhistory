if(!require("EBImage")){
install.packages("BiocManager")
BiocManager::install("EBImage")
}
if(!require("R.matlab")){
install.packages("R.matlab")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("dplyr")){
install.packages("dplyr")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("ggplot2")){
install.packages("ggplot2")
}
if(!require("caret")){
install.packages("caret")
}
if(!require("glmnet")){
install.packages("glmnet")
}
if(!require("WeightedROC")){
install.packages("WeightedROC")
}
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(glmnet)
library(WeightedROC)
load("../output/xgb_res_cv.RData")
setwd("D:/vitual_desktop/akako/gr5243/project3/Spring2021-Project3-group-4-master")
load("../output/xgb_res_cv.RData")
load("D:/vitual_desktop/akako/gr5243/project3/Spring2021-Project3-group-4-master/output/xgb_res_cv.RData")
load("D:/vitual_desktop/akako/gr5243/project3/Spring2021-Project3-group-4-master/output/xgb_fit_train.RData")
View(fit_train)
#install the packages needed
packages.used <- c("EBImage","R.matlab","readxl","dplyr","ggplot2","caret","glmnet",
"WeightedROC","gbm","AUC","MASS","randomForest","pROC", "e1071","xgboost")
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))
if(length(packages.needed) > 0){
install.packages(packages.needed, dependencies = TRUE)
}
if(!require("xgboost")){
install.packages("xgboost")
}
#load libraries
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(glmnet)
library(WeightedROC)
library(gbm)
library(MASS)
library(AUC)
library(randomForest)
library(pROC)
library(e1071)
library(xgboost)
set.seed(2020)
# setwd("~/Project3-FacialEmotionRecognition/doc")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
sample.reweight <- TRUE # run sample reweighting in model training
K <- 5  # number of CV folds
run.feature.train <- TRUE # process features for training set
run.feature.test <- TRUE # process features for test set
#set up controls for baseline(gbm) model
run.cv.gbm <- FALSE # run cross-validation on the training set
run.train.gbm <- TRUE # run evaluation on a training set
run.test.gbm <- TRUE # run evaluation on an independent test set
#set up controls for xgboost model
run.cv.xgb <- FALSE
run.cv.xgb.plot <- TRUE
run.test.xgb <- TRUE
#set up controls for lda model
run.cv.pca <- FALSE
run.pca <- FALSE
run.train.lda <- TRUE
run.test.lda <- TRUE
#set up controls for unweighted random forest model
run.cv.randomForest <- FALSE
run.train.randomForest <- TRUE
run.test.randomForest <- TRUE
#set up controls for weighted random forest model
run.cv.randomForestWeight <- FALSE
run.train.randomForestWeight <- TRUE
run.test.randomForestWeight <- TRUE
#set up controls for elastic net model
run.cv.enet <- FALSE
run.test.enet <- TRUE
#create hyperparameter grid for gbm model (baseline)
hyper_grid_gbm <- expand.grid(
shrinkage = c(0.01, 0.05, 0.1),
n.trees = c(500, 1000, 1500)
)
#create hyperparameter list for xgboost / elastic net
lmbd <- c(1e-3, 5e-3, 1e-2, 5e-2, 1e-1)
model_labels = paste("xgboost with lambda =", lmbd)
#create pc list for lda model
pca.list = c(30, 50, 100, 200, 300, 400, 500, 600)
#create hyperparameter list for random forest model
ntree = c(50, 100, 150, 200, 250)
randomForest_model_labels = paste("Random Forest with number of trees =", ntree)
randomForestWeight_model_labels = paste("randomForestWithWeight with number of trees =", ntree)
#train-test split
info <- read.csv(train_label_path)
#train-test split
info <- read.csv(train_label_path)
n <- nrow(info)
n_train <- round(n*(4/5), 0)
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index, train_idx)
n_files <- length(list.files(train_image_dir))
image_list <- list()
for(i in 1:100){
image_list[[i]] <- readImage(paste0(train_image_dir, sprintf("%04d", i), ".jpg"))
}
#function to read fiducial points
#input: index
#output: matrix of fiducial points corresponding to the index
readMat.matrix <- function(index){
return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}
#load fiducial points
fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(fiducial_pt_list, train_idx))
save(dat_train, file="../output/feature_train.RData")
}else{
load(file="../output/feature_train.RData")
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(fiducial_pt_list, test_idx))
save(dat_test, file="../output/feature_test.RData")
}else{
load(file="../output/feature_test.RData")
}
run.cv.xgb = F
source("../lib/train_XGBoost.R")
source("../lib/test_XGBoost.R")
source("../lib/cross_validation_XGBoost.R")
source("../lib/train_XGBoost.R")
source("../lib/test_XGBoost.R")
source("../lib/cross_vallidation_XGBoost.R")
feature_train = as.matrix(dat_train[, -6007])
label_train = as.integer(dat_train$label)
if(run.cv.xgb){
xgb_res_cv <- matrix(0, nrow = length(lmbd), ncol = 4)
for(i in 1:length(lmbd)){
cat("lambda = ", lmbd[i], "\n")
xgb_res_cv[i,] <- xgbcv.function(features = feature_train, labels = label_train, K,eta_val =0.08,
lmd = lmbd[i],gamma = 0.4,md = 5,nr = 200,  reweight = sample.reweight)
save(xgb_res_cv, file="../output/xgb_res_cv.RData")
}
}else{
load("../output/xgb_res_cv.RData")
}
xgb_res_cv <- as.data.frame(xgb_res_cv)
colnames(xgb_res_cv) <- c("mean_error", "sd_error", "mean_AUC", "sd_AUC")
xgb_res_cv$k = as.factor(lmbd)
if(run.cv.xgb.plot){
p1 <- xgb_res_cv %>%
ggplot(aes(x = as.factor(lmbd), y = mean_error,
ymin = mean_error - sd_error, ymax = mean_error + sd_error)) +
geom_crossbar() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
p2 <- xgb_res_cv %>%
ggplot(aes(x = as.factor(lmbd), y = mean_AUC,
ymin = mean_AUC - sd_AUC, ymax = mean_AUC + sd_AUC)) +
geom_crossbar() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
print(p1)
print(p2)
}
xgb_tm_test = NA
feature_test <- as.matrix(dat_test[, -6007])
if(run.test.xgb){
load(file="../output/xgb_fit_train.RData")
xgb_tm_test <- system.time({prob_pred <- xgbtest(fit_train, feature_test);
label_pred <- ifelse(prob_pred >= 0.5, 1, 0)})
}
#evaluation
## reweight the test data to represent a balanced label distribution
label_test <- as.integer(dat_test$label)
label_test <- ifelse(label_test == 2, 0, 1)
weight_test <- rep(NA, length(label_test))
for (v in unique(label_test)){
weight_test[label_test == v] = 0.5 * length(label_test) / length(label_test[label_test == v])
}
accu_xgboost <- sum(weight_test * (label_pred == label_test)) / sum(weight_test)
tpr.fpr <- WeightedROC(prob_pred, label_test, weight_test)
auc_xgboost <- WeightedAUC(tpr.fpr)
cat("The accuracy of model:", model_labels[which.max(xgb_res_cv$mean_AUC)], "is", accu*100, "%.\n")
xgb_tm_test = NA
feature_test <- as.matrix(dat_test[, -6007])
if(run.test.xgb){
load(file="../output/xgb_fit_train.RData")
xgb_tm_test <- system.time({prob_pred <- xgbtest(fit_train, feature_test);
label_pred <- ifelse(prob_pred >= 0.5, 1, 0)})
}
#evaluation
## reweight the test data to represent a balanced label distribution
label_test <- as.integer(dat_test$label)
label_test <- ifelse(label_test == 2, 0, 1)
weight_test <- rep(NA, length(label_test))
for (v in unique(label_test)){
weight_test[label_test == v] = 0.5 * length(label_test) / length(label_test[label_test == v])
}
accu_xgboost <- sum(weight_test * (label_pred == label_test)) / sum(weight_test)
tpr.fpr <- WeightedROC(prob_pred, label_test, weight_test)
auc_xgboost <- WeightedAUC(tpr.fpr)
cat("The accuracy of model:", model_labels[which.max(xgb_res_cv$mean_AUC)], "is", accu_xgboost*100, "%.\n")
cat("The AUC of model:", model_labels[which.max(xgb_res_cv$mean_AUC)], "is", auc_xgboost, ".\n")
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
cat("Time for training model=", xgb_tm_train[1], "s \n")
par_best <- lmbd[which.min(xgb_res_cv$mean_AUC)] # lmbd[which.max(res_cv$mean_AUC)]
weight_train <- rep(NA, length(label_train))
for (v in unique(label_train)){
weight_train[label_train == v] = 0.5 * length(label_train) / length(label_train[label_train == v])
}
if (sample.reweight){
xgb_tm_train <- system.time(fit_train <- xgbtrain(feature_train, label_train, w = weight_train, eta_val = 0.08 ,gamma = 0.4, lmd = par_best, nr = 200, md = 5))
} else {
xgb_tm_train <- system.time(fit_train <- xgbtrain(feature_train, label_train, w = NULL, eta_val = 0.08 ,gamma = 0.4, lmd = par_best, nr = 200, md = 5))
}
save(fit_train, file="../output/xgb_fit_train.RData")
xgb_tm_test = NA
feature_test <- as.matrix(dat_test[, -6007])
if(run.test.xgb){
load(file="../output/xgb_fit_train.RData")
xgb_tm_test <- system.time({prob_pred <- xgbtest(fit_train, feature_test);
label_pred <- ifelse(prob_pred >= 0.5, 1, 0)})
}
#evaluation
## reweight the test data to represent a balanced label distribution
label_test <- as.integer(dat_test$label)
label_test <- ifelse(label_test == 2, 0, 1)
weight_test <- rep(NA, length(label_test))
for (v in unique(label_test)){
weight_test[label_test == v] = 0.5 * length(label_test) / length(label_test[label_test == v])
}
accu_xgboost <- sum(weight_test * (label_pred == label_test)) / sum(weight_test)
tpr.fpr <- WeightedROC(prob_pred, label_test, weight_test)
auc_xgboost <- WeightedAUC(tpr.fpr)
cat("The accuracy of model:", model_labels[which.max(xgb_res_cv$mean_AUC)], "is", accu_xgboost*100, "%.\n")
cat("The AUC of model:", model_labels[which.max(xgb_res_cv$mean_AUC)], "is", auc_xgboost, ".\n")
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
cat("Time for training model=", xgb_tm_train[1], "s \n")
cat("Time for testing model=", xgb_tm_test[1], "s \n")
source("../lib/train_XGBoost.R")
source("../lib/test_XGBoost.R")
source("../lib/cross_vallidation_XGBoost.R")
feature_train = as.matrix(dat_train[, -6007])
label_train = as.integer(dat_train$label)
if(run.cv.xgb){
xgb_res_cv <- matrix(0, nrow = length(lmbd), ncol = 4)
for(i in 1:length(lmbd)){
cat("lambda = ", lmbd[i], "\n")
xgb_res_cv[i,] <- xgbcv.function(features = feature_train, labels = label_train, K,eta_val =0.08,
lmd = lmbd[i],gamma = 0.4,md = 5,nr = 200,  reweight = sample.reweight)
save(xgb_res_cv, file="../output/xgb_res_cv.RData")
}
}else{
load("../output/xgb_res_cv.RData")
}
par_best <- lmbd[which.min(xgb_res_cv$mean_error)] # lmbd[which.max(res_cv$mean_AUC)]
packages.used <- c("EBImage","R.matlab","readxl","dplyr","ggplot2","caret",
"glmnet","WeightedROC","gbm","xgboost", "AUC")
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))
if(length(packages.needed) > 0){
install.packages(packages.needed, dependencies = TRUE)
}
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(glmnet)
library(WeightedROC)
library(gbm)
library(xgboost)
library(AUC)
#change to testset folder name on presentation day
#test_dir <- "../data/test_set/"
test_dir <- "../data/train-set/"
test_image_dir <- paste(test_dir, "images/", sep="")
test_pt_dir <- paste(test_dir,  "points/", sep="")
test_label_path <- paste(test_dir, "label_prediction.csv", sep="")
n_files <- length(list.files(test_image_dir))
#readMat.matrix <- function(index){
#  return(round(readMat(paste0(test_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
#}
#fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
load(file="../output/fiducial_pt_list.RData")
#features
#Index <- c(1:n_files)
#info = data.frame(Index)
#info$label = rep(-1, n_files)
#test_idx <- c(1:n_files)
source("../lib/feature.R")
tm_feature_test <- NA
tm_feature_test <- system.time(dat_test <- feature(fiducial_pt_list, test_idx))
feature_test <- as.matrix(dat_test[, -6007])
load(file="../output/fit_train_gbm.RData")
load(file="../output/xgb_fit_train.RData")
source("../lib/test_XGBoost.R")
prob_pred_xgboost <- xgbtest(xgb_fit_train, feature_test)
load(file="../output/xgb_fit_train.RData")
source("../lib/test_XGBoost.R")
prob_pred_xgboost <- xgbtest(xgb_fit_train, feature_test)
load(file="../output/xgb_fit_train.RData")
source("../lib/test_XGBoost.R")
prob_pred_xgboost <- xgbtest(fit_train, feature_test)
label_pred_xgboost <- ifelse(prob_pred_xgboost >= 0.5, 1, 0)
info <- read.csv(train_label_path)
info <- read.csv(test_label_path)
label_pred_xgboost
